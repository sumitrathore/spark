{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting survival of passengers in Titanic dataset\n",
    "Link: https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"spark://localhost:7077\").appName(\"Predicting survivals in titanic\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = spark.read.csv(\"file:///home/user/titanic_dataset/train.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = spark.read.csv(\"file:///home/user/titanic_dataset/test.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_data = train_data.drop('Survived').unionByName(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combine_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: int, Pclass: int, Name: string, Sex: string, Age: double, SibSp: int, Parch: int, Ticket: string, Fare: double, Cabin: string, Embarked: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Pclass|Name                                               |Sex   |Age |SibSp|Parch|Ticket          |Fare   |Cabin|Embarked|\n",
      "+-----------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|1          |3     |Braund, Mr. Owen Harris                            |male  |22.0|1    |0    |A/5 21171       |7.25   |null |S       |\n",
      "|2          |1     |Cumings, Mrs. John Bradley (Florence Briggs Thayer)|female|38.0|1    |0    |PC 17599        |71.2833|C85  |C       |\n",
      "|3          |3     |Heikkinen, Miss. Laina                             |female|26.0|0    |0    |STON/O2. 3101282|7.925  |null |S       |\n",
      "|4          |1     |Futrelle, Mrs. Jacques Heath (Lily May Peel)       |female|35.0|1    |0    |113803          |53.1   |C123 |S       |\n",
      "|5          |3     |Allen, Mr. William Henry                           |male  |35.0|0    |0    |373450          |8.05   |null |S       |\n",
      "|6          |3     |Moran, Mr. James                                   |male  |null|0    |0    |330877          |8.4583 |null |Q       |\n",
      "|7          |1     |McCarthy, Mr. Timothy J                            |male  |54.0|0    |0    |17463           |51.8625|E46  |S       |\n",
      "|8          |3     |Palsson, Master. Gosta Leonard                     |male  |2.0 |3    |1    |349909          |21.075 |null |S       |\n",
      "|9          |3     |Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  |female|27.0|0    |2    |347742          |11.1333|null |S       |\n",
      "|10         |2     |Nasser, Mrs. Nicholas (Adele Achem)                |female|14.0|1    |0    |237736          |30.0708|null |C       |\n",
      "+-----------+------+---------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combine_data.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_data = combine_data.withColumn('Title',F.regexp_extract(F.col('Name'), '.*,\\ (\\w+).*', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_data = combine_data.drop('Name','Ticket','Fare','Cabin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = combine_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countNull(df,var):\n",
    "    return df.where(df[var].isNull()).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = {var: countNull(combine_data,var) for var in columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': 263,\n",
       " 'Embarked': 2,\n",
       " 'Parch': 0,\n",
       " 'PassengerId': 0,\n",
       " 'Pclass': 0,\n",
       " 'Sex': 0,\n",
       " 'SibSp': 0,\n",
       " 'Title': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_age = combine_data.groupBy().agg(F.avg('Age')).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_data = combine_data.na.fill({'Age': avg_age})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_data = combine_data.na.fill({'Embarked': 'S'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_data = combine_data.withColumn('Family', F.col('SibSp')+F.col('Parch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = combine_data.filter(combine_data['PassengerId']<= 891)\n",
    "test = combine_data.filter(combine_data['PassengerId'] > 891)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.join(train_data.select('PassengerId','Survived'), ['PassengerId'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------+------------------+-----+-----+--------+------+------+--------+\n",
      "|PassengerId|Pclass|   Sex|               Age|SibSp|Parch|Embarked| Title|Family|Survived|\n",
      "+-----------+------+------+------------------+-----+-----+--------+------+------+--------+\n",
      "|          1|     3|  male|              22.0|    1|    0|       S|    Mr|     1|       0|\n",
      "|          2|     1|female|              38.0|    1|    0|       C|   Mrs|     1|       1|\n",
      "|          3|     3|female|              26.0|    0|    0|       S|  Miss|     0|       1|\n",
      "|          4|     1|female|              35.0|    1|    0|       S|   Mrs|     1|       1|\n",
      "|          5|     3|  male|              35.0|    0|    0|       S|    Mr|     0|       0|\n",
      "|          6|     3|  male|29.881137667304014|    0|    0|       Q|    Mr|     0|       0|\n",
      "|          7|     1|  male|              54.0|    0|    0|       S|    Mr|     0|       0|\n",
      "|          8|     3|  male|               2.0|    3|    1|       S|Master|     4|       0|\n",
      "|          9|     3|female|              27.0|    0|    2|       S|   Mrs|     2|       1|\n",
      "|         10|     2|female|              14.0|    1|    0|       C|   Mrs|     1|       1|\n",
      "|         11|     3|female|               4.0|    1|    1|       S|  Miss|     2|       1|\n",
      "|         12|     1|female|              58.0|    0|    0|       S|  Miss|     0|       1|\n",
      "|         13|     3|  male|              20.0|    0|    0|       S|    Mr|     0|       0|\n",
      "|         14|     3|  male|              39.0|    1|    5|       S|    Mr|     6|       0|\n",
      "|         15|     3|female|              14.0|    0|    0|       S|  Miss|     0|       0|\n",
      "|         16|     2|female|              55.0|    0|    0|       S|   Mrs|     0|       1|\n",
      "|         17|     3|  male|               2.0|    4|    1|       Q|Master|     5|       0|\n",
      "|         18|     2|  male|29.881137667304014|    0|    0|       S|    Mr|     0|       1|\n",
      "|         19|     3|female|              31.0|    1|    0|       S|   Mrs|     1|       0|\n",
      "|         20|     3|female|29.881137667304014|    0|    0|       C|   Mrs|     0|       1|\n",
      "+-----------+------+------+------------------+-----+-----+--------+------+------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': 0,\n",
       " 'Embarked': 0,\n",
       " 'Parch': 0,\n",
       " 'PassengerId': 0,\n",
       " 'Pclass': 0,\n",
       " 'Sex': 0,\n",
       " 'SibSp': 0,\n",
       " 'Title': 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = {var: countNull(combine_data,var) for var in columns}\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = false)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Embarked: string (nullable = false)\n",
      " |-- Title: string (nullable = true)\n",
      " |-- Family: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "combine_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,OneHotEncoder,StringIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_indexer = StringIndexer(inputCol='Sex',outputCol='SexIndex')\n",
    "gender_encoder = OneHotEncoder(inputCol='SexIndex',outputCol='SexEnc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embark_indexer = StringIndexer(inputCol='Embarked',outputCol='EmbarkIndex')\n",
    "embark_encoder = OneHotEncoder(inputCol='EmbarkIndex',outputCol='EmbarkEnc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_indexer = StringIndexer(inputCol='Title',outputCol='TitleIndex')\n",
    "title_encoder = OneHotEncoder(inputCol='TitleIndex',outputCol='TitleEnc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_encoder = OneHotEncoder(inputCol='Pclass',outputCol='PclassEnc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['PclassEnc',\n",
    " 'SexEnc',\n",
    " 'Age',\n",
    " 'Family',\n",
    " 'EmbarkEnc',\n",
    " 'TitleEnc'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_titanic = LogisticRegression(featuresCol='features',labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[gender_indexer,embark_indexer,\n",
    "                           gender_encoder,embark_encoder,\n",
    "                           title_indexer, title_encoder,\n",
    "                           pclass_encoder,\n",
    "                           assembler,log_reg_titanic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fit_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|PassengerId|prediction|\n",
      "+-----------+----------+\n",
      "|        892|       0.0|\n",
      "|        893|       1.0|\n",
      "|        894|       0.0|\n",
      "|        895|       0.0|\n",
      "|        896|       1.0|\n",
      "|        897|       0.0|\n",
      "|        898|       1.0|\n",
      "|        899|       0.0|\n",
      "|        900|       1.0|\n",
      "|        901|       0.0|\n",
      "|        902|       0.0|\n",
      "|        903|       0.0|\n",
      "|        904|       1.0|\n",
      "|        905|       0.0|\n",
      "|        906|       1.0|\n",
      "|        907|       1.0|\n",
      "|        908|       0.0|\n",
      "|        909|       0.0|\n",
      "|        910|       1.0|\n",
      "|        911|       1.0|\n",
      "+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select('PassengerId','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
